{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "## Implemented earlystopping with val_loss \n",
    "\n",
    "From, https://stackoverflow.com/questions/43906048/keras-early-stopping\n",
    "It is likely that val_loss is happening on test sets specified in this notebook\n",
    "\"Monitor the validation loss (need to use cross validation or at least train/test sets) by setting the monitor argument to 'val_loss'.\"\n",
    "\n",
    "## Implementing skip connection\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the right libraries\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 'arrythmia_type']\n"
     ]
    }
   ],
   "source": [
    "column_names = list(range(187))\n",
    "print(column_names)\n",
    "\n",
    "column_names.append('arrythmia_type')\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamga\\OneDrive\\Desktop\\Desktop_folder\\Data_Science\\Springboard\\Data\\heartbeat\n"
     ]
    }
   ],
   "source": [
    "data_path =r'C:\\Users\\iamga\\OneDrive\\Desktop\\Desktop_folder\\Data_Science\\Springboard\\Data\\heartbeat'\n",
    "\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87554, 188)\n",
      "(21892, 188)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>arrythmia_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758264</td>\n",
       "      <td>0.111570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.078512</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908425</td>\n",
       "      <td>0.783883</td>\n",
       "      <td>0.531136</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.730088</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.399329</td>\n",
       "      <td>0.238255</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.758264  0.111570  0.000000  0.080579  0.078512  0.066116   \n",
       "1  0.908425  0.783883  0.531136  0.362637  0.366300  0.344322  0.333333   \n",
       "2  0.730088  0.212389  0.000000  0.119469  0.101770  0.101770  0.110619   \n",
       "3  1.000000  0.910417  0.681250  0.472917  0.229167  0.068750  0.000000   \n",
       "4  0.570470  0.399329  0.238255  0.147651  0.000000  0.003356  0.040268   \n",
       "\n",
       "          7         8         9       ...        178  179  180  181  182  183  \\\n",
       "0  0.049587  0.047521  0.035124       ...        0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.307692  0.296703  0.300366       ...        0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.123894  0.115044  0.132743       ...        0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.004167  0.014583  0.054167       ...        0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.080537  0.070470  0.090604       ...        0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   184  185  186  arrythmia_type  \n",
       "0  0.0  0.0  0.0             0.0  \n",
       "1  0.0  0.0  0.0             0.0  \n",
       "2  0.0  0.0  0.0             0.0  \n",
       "3  0.0  0.0  0.0             0.0  \n",
       "4  0.0  0.0  0.0             0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training data\n",
    "\n",
    "    \n",
    "df_train = pd.read_csv(data_path+'\\mitbih_train.csv', header=None, names=column_names)\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head()\n",
    "\n",
    "# load the testing data\n",
    "\n",
    "df_test = pd.read_csv(data_path+'\\mitbih_test.csv', header=None, names=column_names)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21892, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_train = df_train.drop(labels=['arrythmia_type'], axis=1)\n",
    "\n",
    "predictors_train.shape\n",
    "\n",
    "target_train = to_categorical(df_train.arrythmia_type)\n",
    "target_train.shape\n",
    "\n",
    "predictors_test = df_test.drop(labels=['arrythmia_type'], axis=1)\n",
    "\n",
    "predictors_test.shape\n",
    "\n",
    "target_test = to_categorical(df_test.arrythmia_type)\n",
    "target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(number_training_datapoints, number_features) = predictors_train.shape\n",
    "number_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying F1 score from \n",
    "https://stackoverflow.com/questions/45411902/how-to-use-f1-score-with-keras-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(y_pred, y_true):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a 1 layer network\n",
    "\n",
    "n_cols = 187\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=[n_cols,]))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "87554/87554 [==============================] - 6s 72us/step - loss: 0.4206 - acc: 0.8845 - f1_score: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2276fa90b70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with training data\n",
    "model.fit(predictors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21892/21892 [==============================] - 1s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30126758106835644, 0.9143522748035812, nan]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on test data\n",
    "\n",
    "model.evaluate(predictors_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>arrythmia_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "      <td>87554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.890360</td>\n",
       "      <td>0.758160</td>\n",
       "      <td>0.423972</td>\n",
       "      <td>0.219104</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>0.210399</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>0.201773</td>\n",
       "      <td>0.198691</td>\n",
       "      <td>0.196757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.473376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240909</td>\n",
       "      <td>0.221813</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.206878</td>\n",
       "      <td>0.177058</td>\n",
       "      <td>0.171909</td>\n",
       "      <td>0.178481</td>\n",
       "      <td>0.177240</td>\n",
       "      <td>0.171778</td>\n",
       "      <td>0.168357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>1.143184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.921922</td>\n",
       "      <td>0.682486</td>\n",
       "      <td>0.250969</td>\n",
       "      <td>0.048458</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>0.088416</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.068639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.991342</td>\n",
       "      <td>0.826013</td>\n",
       "      <td>0.429472</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.147878</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.148734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.578767</td>\n",
       "      <td>0.341727</td>\n",
       "      <td>0.258993</td>\n",
       "      <td>0.287628</td>\n",
       "      <td>0.298237</td>\n",
       "      <td>0.295391</td>\n",
       "      <td>0.290832</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.890360      0.758160      0.423972      0.219104      0.201127   \n",
       "std        0.240909      0.221813      0.227305      0.206878      0.177058   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.921922      0.682486      0.250969      0.048458      0.082329   \n",
       "50%        0.991342      0.826013      0.429472      0.166000      0.147878   \n",
       "75%        1.000000      0.910506      0.578767      0.341727      0.258993   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.210399      0.205808      0.201773      0.198691      0.196757   \n",
       "std        0.171909      0.178481      0.177240      0.171778      0.168357   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.088416      0.073333      0.066116      0.065000      0.068639   \n",
       "50%        0.158798      0.145324      0.144424      0.150000      0.148734   \n",
       "75%        0.287628      0.298237      0.295391      0.290832      0.283636   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            ...                 178           179           180           181  \\\n",
       "count       ...        87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean        ...            0.005025      0.004628      0.004291      0.003945   \n",
       "std         ...            0.044154      0.042089      0.040525      0.038651   \n",
       "min         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "25%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "50%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "75%         ...            0.000000      0.000000      0.000000      0.000000   \n",
       "max         ...            1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                182           183           184           185           186  \\\n",
       "count  87554.000000  87554.000000  87554.000000  87554.000000  87554.000000   \n",
       "mean       0.003681      0.003471      0.003221      0.002945      0.002807   \n",
       "std        0.037193      0.036255      0.034789      0.032865      0.031924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       arrythmia_type  \n",
       "count    87554.000000  \n",
       "mean         0.473376  \n",
       "std          1.143184  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          4.000000  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72471.,  2223.,  5788.,   641.,  6431.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_test_transpose = predictors_test.T\n",
    "\n",
    "predictors_test_transpose.iloc[:,:10].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors_test_transpose.iloc[:,2:4].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement deep learning archtechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Convolution1D, Add, Activation\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "#from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 187)\n",
      "(21892, 187, 1)\n",
      "(87554, 187, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictors_test.shape)\n",
    "\n",
    "predictors_test_CNN = np.expand_dims(predictors_test, axis=2)\n",
    "\n",
    "print(predictors_test_CNN.shape)\n",
    "\n",
    "predictors_train_CNN = np.expand_dims(predictors_train, axis=2)\n",
    "print(predictors_train_CNN.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 187, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 187, 32)      192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 187, 32)      5152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 187, 32)      5152        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 187, 32)      0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 187, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 94, 32)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3008)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           96288       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            165         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 106,949\n",
      "Trainable params: 106,949\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(187, 1))\n",
    "\n",
    "x1 = Convolution1D(filters=32, kernel_size=5, activation='linear', input_shape=( number_features, 1), padding='same')(input_data)\n",
    "\n",
    "# 5 residual blocks\n",
    "x = Convolution1D(filters=32, kernel_size=5, activation='relu', padding='same' )(x1)\n",
    "x = Convolution1D(filters=32, kernel_size=5, activation='linear', padding='same')(x)\n",
    "\n",
    "joinedTensor = Add()([x,x1])\n",
    "\n",
    "joinedTensor = Activation('relu')(joinedTensor)\n",
    "joinedTensor = MaxPooling1D(pool_size=(5), strides=(2), padding='same')(joinedTensor)\n",
    "\n",
    "joinedTensor = Flatten()(joinedTensor)\n",
    "joinedTensor = Dense(32, activation='relu')(joinedTensor)\n",
    "\n",
    "joinedTensor = Dense(5, activation='softmax')(joinedTensor)\n",
    "\n",
    "model_with_skip = Model(input_data, joinedTensor)\n",
    "model_with_skip.summary()\n",
    "\n",
    "model_with_skip.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87554 samples, validate on 21892 samples\n",
      "Epoch 1/100\n",
      "87554/87554 [==============================] - 95s 1ms/step - loss: 0.1659 - acc: 0.9536 - val_loss: 0.1035 - val_acc: 0.9730\n",
      "Epoch 2/100\n",
      "87554/87554 [==============================] - 97s 1ms/step - loss: 0.0875 - acc: 0.9758 - val_loss: 0.0897 - val_acc: 0.9759\n",
      "Epoch 3/100\n",
      "87554/87554 [==============================] - 96s 1ms/step - loss: 0.0701 - acc: 0.9798 - val_loss: 0.0836 - val_acc: 0.9792\n",
      "Epoch 4/100\n",
      "87554/87554 [==============================] - 96s 1ms/step - loss: 0.0594 - acc: 0.9825 - val_loss: 0.0729 - val_acc: 0.9810\n",
      "Epoch 5/100\n",
      "87554/87554 [==============================] - 107s 1ms/step - loss: 0.0501 - acc: 0.9851 - val_loss: 0.0792 - val_acc: 0.9785\n",
      "Epoch 6/100\n",
      "87554/87554 [==============================] - 99s 1ms/step - loss: 0.0441 - acc: 0.9864 - val_loss: 0.0725 - val_acc: 0.9793\n",
      "Epoch 7/100\n",
      "87554/87554 [==============================] - 97s 1ms/step - loss: 0.0397 - acc: 0.9878 - val_loss: 0.0764 - val_acc: 0.9818\n",
      "Epoch 8/100\n",
      "87554/87554 [==============================] - 106s 1ms/step - loss: 0.0362 - acc: 0.9887 - val_loss: 0.0764 - val_acc: 0.9796\n",
      "Epoch 9/100\n",
      "87554/87554 [==============================] - 100s 1ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.0717 - val_acc: 0.9826\n",
      "Epoch 10/100\n",
      "87554/87554 [==============================] - 100s 1ms/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0804 - val_acc: 0.9815\n",
      "Epoch 11/100\n",
      "87554/87554 [==============================] - 105s 1ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 0.0754 - val_acc: 0.9833\n",
      "Epoch 12/100\n",
      "87554/87554 [==============================] - 99s 1ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0737 - val_acc: 0.9834\n"
     ]
    }
   ],
   "source": [
    "CNN_with_skip_history = model_with_skip.fit(predictors_train_CNN, target_train, epochs=100, validation_data=(predictors_test_CNN, target_test), callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model as a fucntion with parameter # of cnn stacks\n",
    "# the the fucntion in for loop and collate teh accruracy for difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "model_CNN = Sequential()\n",
    "\n",
    "model_CNN.add(Convolution1D(filters=32, kernel_size=5, activation='linear', input_shape=( number_features, 1)))\n",
    "\n",
    "\n",
    "# 5 residual blocks\n",
    "model_CNN.add(Convolution1D(filters=32, kernel_size=5, activation='relu'))\n",
    "model_CNN.add(Convolution1D(filters=32, kernel_size=5, activation='relu'))\n",
    "model_CNN.add(MaxPooling1D(pool_size=(5), strides=(2)))\n",
    "\n",
    "\n",
    "# outermost layers\n",
    "model_CNN.add(Dense(32, activation='relu'))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model_CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 183, 32)           192       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 179, 32)           5152      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 175, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 86, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 86, 32)            1056      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2752)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 13765     \n",
      "=================================================================\n",
      "Total params: 25,317\n",
      "Trainable params: 25,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the input to the CNN so that the convolution1D can work\n",
    "https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d/43399308#43399308\n",
    "\n",
    "https://stackoverflow.com/questions/38656566/input-dimensions-to-a-one-dimensional-convolutional-network-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87554, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87554 samples, validate on 21892 samples\n",
      "Epoch 1/100\n",
      "87554/87554 [==============================] - 100s 1ms/step - loss: 0.1926 - acc: 0.9471 - f1_score: nan - val_loss: 0.1248 - val_acc: 0.9665 - val_f1_score: 0.9664\n",
      "Epoch 2/100\n",
      "87554/87554 [==============================] - 93s 1ms/step - loss: 0.1030 - acc: 0.9713 - f1_score: 0.9713 - val_loss: 0.1038 - val_acc: 0.9731 - val_f1_score: 0.9728\n",
      "Epoch 3/100\n",
      "87554/87554 [==============================] - 94s 1ms/step - loss: 0.0845 - acc: 0.9760 - f1_score: 0.9759 - val_loss: 0.0877 - val_acc: 0.9764 - val_f1_score: 0.9763\n",
      "Epoch 4/100\n",
      "87554/87554 [==============================] - 99s 1ms/step - loss: 0.0736 - acc: 0.9788 - f1_score: 0.9789 - val_loss: 0.0952 - val_acc: 0.9740 - val_f1_score: 0.9742\n",
      "Epoch 5/100\n",
      "87554/87554 [==============================] - 92s 1ms/step - loss: 0.0651 - acc: 0.9811 - f1_score: 0.9812 - val_loss: 0.0966 - val_acc: 0.9759 - val_f1_score: 0.9758\n",
      "Epoch 6/100\n",
      "87554/87554 [==============================] - 94s 1ms/step - loss: 0.0595 - acc: 0.9826 - f1_score: 0.9826 - val_loss: 0.0916 - val_acc: 0.9767 - val_f1_score: 0.9766\n"
     ]
    }
   ],
   "source": [
    "# fit the model with training data\n",
    "CNN_history = model_CNN.fit(predictors_train_CNN, target_train, epochs=100, validation_data=(predictors_test_CNN, target_test), callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train[80000]\n",
    "\n",
    "np.argmax(target_train[80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_val_acc = CNN_history.history['val_acc']\n",
    "\n",
    "plt.plot(CNN_val_acc)\n",
    "plt.ylim([0.9 , 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "\n",
    "predicted_test = model_CNN.predict(predictors_test_CNN)\n",
    "predicted_test = np.argmax(predicted_test, axis = 1)\n",
    "#(target_test)\n",
    "\n",
    "#confusion_matrix([0, 1,2 , 3, 0], [0, 2, 3, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18012   155   105    55    32]\n",
      " [   60   390     7     0     0]\n",
      " [   35    10  1313    10     5]\n",
      " [    1     1    18    97     0]\n",
      " [   10     0     5     0  1571]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_CNN = confusion_matrix(predicted_test, df_test.arrythmia_type)\n",
    "print(confusion_matrix_CNN)\n",
    "#predicted_test[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.981 0.008 0.006 0.003 0.002]\n",
      " [0.131 0.853 0.015 0.    0.   ]\n",
      " [0.025 0.007 0.956 0.007 0.004]\n",
      " [0.009 0.009 0.154 0.829 0.   ]\n",
      " [0.006 0.    0.003 0.    0.991]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9220786039688266"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(confusion_matrix_)\n",
    "normalized_confusion_matrix_CNN = confusion_matrix_CNN/confusion_matrix_CNN.sum(axis = 1, keepdims = True)\n",
    "\n",
    "print(np.around(normalized_confusion_matrix_CNN, 3))\n",
    "\n",
    "np.mean(np.diag(normalized_confusion_matrix_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison to paper: Number of sample points in each category, also normalization\n",
    "# Skip connection: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 12.3.1 in springboard\n",
    "\n",
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, callbacks=[early_stopping_monitor], epochs=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
